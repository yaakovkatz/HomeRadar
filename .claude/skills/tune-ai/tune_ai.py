#!/usr/bin/env python3
"""
ğŸ¯ Tune AI - ××•×˜×•××¦×™×” ×œ×¢×“×›×•×Ÿ ×”×’×“×¨×•×ª AI

×¡×•×¨×§ ××ª ×‘×¡×™×¡ ×”× ×ª×•× ×™×, ××•×¦× ×“×¤×•×¡×™×, ×•××¦×™×¢ ×¢×“×›×•× ×™× ××•×˜×•××˜×™×™×:
- ××ª×•×•×›×™× ×—×“×©×™×
- ×™×™×©×•×‘×™× ×œ× ×¨×œ×•×•× ×˜×™×™×
- ×‘×™×˜×•×™×™× ×œblacklist

Usage:
    python tune_ai.py                  # ×¨×§ ×¡×§×™×¨×”
    python tune_ai.py --interactive    # ××™× ×˜×¨××§×˜×™×‘×™
    python tune_ai.py --apply          # ××•×˜×•××˜×™ ××œ×
    python tune_ai.py --report         # ×“×•×— ××¤×•×¨×˜
"""

import sqlite3
import json
import re
import argparse
from datetime import datetime
from collections import Counter
import os
import shutil

class TuneAI:
    def __init__(self, db_path="posts.db", config_path="config.json"):
        self.db_path = db_path
        self.config_path = config_path
        self.recommendations = {
            'brokers': [],
            'publishers_for_brokers': [],  # ××¤×¨×¡××™× ×©×¢×•×‘×“×™× ×¢×‘×•×¨ ××ª×•×•×›×™×
            'settlements': [],
            'blacklist': [],
            'spam': [],
            'repeat_posters': [],
            'misclassified': []
        }

    def analyze(self):
        """×¡×¨×™×§×” ××œ××” ×©×œ ×”DB + ×”××œ×¦×•×ª"""
        print("\n" + "=" * 70)
        print("ğŸ¯ Tune AI - ×¡×¨×™×§×ª ×‘×¡×™×¡ × ×ª×•× ×™×")
        print("=" * 70 + "\n")

        # 1. ×¡×˜×˜×™×¡×˜×™×§×•×ª ×‘×¡×™×¡×™×•×ª
        stats = self._get_stats()
        self._print_stats(stats)

        # 2. ×–×™×”×•×™ ××ª×•×•×›×™× ×—×“×©×™×
        print("\n" + "-" * 70)
        print("ğŸ” ××—×¤×© ××ª×•×•×›×™× ×—×“×©×™×...")
        self._find_new_brokers()

        # 2.5. ×–×™×”×•×™ ××¤×¨×¡××™× ×©×¢×•×‘×“×™× ×¢×‘×•×¨ ××ª×•×•×›×™×
        print("\n" + "-" * 70)
        print("ğŸ‘¤ ××—×¤×© ××¤×¨×¡××™× ×©×¢×•×‘×“×™× ×¢×‘×•×¨ ××ª×•×•×›×™×...")
        self._find_publishers_for_brokers()

        # 3. ×–×™×”×•×™ ×™×™×©×•×‘×™×
        print("\n" + "-" * 70)
        print("ğŸ˜ï¸ ××—×¤×© ×™×™×©×•×‘×™× ×œ× ×¨×œ×•×•× ×˜×™×™×...")
        self._find_settlements()

        # 4. ×‘×™×˜×•×™×™× ×œblacklist
        print("\n" + "-" * 70)
        print("ğŸš« ××—×¤×© ×‘×™×˜×•×™×™× ×—×“×©×™× ×œ×—×¡×™××”...")
        self._find_blacklist_terms()

        # 5. ×–×™×”×•×™ ×¤×•×¡×˜×™× ×—×•×–×¨×™×
        print("\n" + "-" * 70)
        print("ğŸ” ××—×¤×© ××©×ª××©×™× ×©××¤×¨×¡××™× ×”×¨×‘×” ×¤×¢××™×...")
        self._find_repeat_posters()

        # 6. ×–×™×”×•×™ ×¤×•×¡×˜×™× ×©×¡×•×•×’×• ×œ× × ×›×•×Ÿ
        print("\n" + "-" * 70)
        print("âš ï¸ ××—×¤×© ×¤×•×¡×˜×™× ×©××•×œ×™ ×¡×•×•×’×• ×œ× × ×›×•×Ÿ...")
        self._find_misclassified_posts()

        # 7. ×¡×™×›×•× ×”××œ×¦×•×ª
        print("\n" + "=" * 70)
        self._print_recommendations()

    def _get_stats(self):
        """×¡×˜×˜×™×¡×˜×™×§×•×ª ×‘×¡×™×¡×™×•×ª"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()

            stats = {}

            # ×¡×”"×› ×¤×•×¡×˜×™×
            cursor.execute("SELECT COUNT(*) FROM posts")
            stats['total'] = cursor.fetchone()[0]

            # ×¨×œ×•×•× ×˜×™×™×
            cursor.execute("SELECT COUNT(*) FROM posts WHERE is_relevant = 1")
            stats['relevant'] = cursor.fetchone()[0]

            # ××ª×•×•×›×™×
            cursor.execute("SELECT COUNT(*) FROM posts WHERE is_broker = 1")
            stats['brokers'] = cursor.fetchone()[0]

            # NON_URBAN
            cursor.execute("SELECT COUNT(*) FROM posts WHERE category = 'NON_URBAN'")
            stats['non_urban'] = cursor.fetchone()[0]

            # SPAM
            cursor.execute("SELECT COUNT(*) FROM posts WHERE category IN ('SPAM', 'WANTED')")
            stats['spam'] = cursor.fetchone()[0]

            return stats

    def _print_stats(self, stats):
        """×”×“×¤×¡×ª ×¡×˜×˜×™×¡×˜×™×§×•×ª"""
        print("ğŸ“Š ×¡×˜×˜×™×¡×˜×™×§×•×ª:")
        print(f"  ğŸ“ ×¡×”\"×› ×¤×•×¡×˜×™×: {stats['total']}")
        print(f"  âœ… ×¨×œ×•×•× ×˜×™×™×: {stats['relevant']}")
        print(f"  ğŸš« ××ª×•×•×›×™× × ×—×¡××•: {stats['brokers']}")
        print(f"  ğŸ˜ï¸ ×™×™×©×•×‘×™× ×œ× ×¨×œ×•×•× ×˜×™×™×: {stats['non_urban']}")
        print(f"  âš ï¸ ×¡×¤××: {stats['spam']}")

    def _find_new_brokers(self):
        """××•×¦× ×©××•×ª ××ª×•×•×›×™× ×—×“×©×™× - ×’× ×—×‘×¨×•×ª ×•×’× ×©××•×ª ×¤×¨×˜×™×™×"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()

            # ×©×œ×•×£ ×¤×•×¡×˜×™× ×©×¡×•×× ×• ×›××ª×•×•×›×™× ××• ×—×©×•×“×™×
            cursor.execute("""
                SELECT post_id, content, author, ai_reason, category
                FROM posts
                WHERE is_broker = 1 OR category = 'BROKER' OR category = 'SUSPECTED_BROKER'
                LIMIT 100
            """)

            broker_posts = cursor.fetchall()

        # ×˜×¢×Ÿ broker_keywords ×§×™×™××™×
        with open(self.config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        existing_keywords = set(kw.lower() for kw in config['search_settings']['search_settings']['broker_keywords'])

        # ×—×œ×¥ ×©××•×ª ×—×‘×¨×•×ª + ×©××•×ª ×¤×¨×˜×™×™×
        broker_names = []
        suspected_names = []  # ×¨×©×™××” × ×¤×¨×“×ª ×œ×—×©×•×“×™×

        # ××™×œ×•× ×™× ×œ×©××™×¨×ª ×”×¤×•×¡×˜×™× ×œ×¤×™ ×©× ××ª×•×•×š
        broker_posts_dict = {}  # {broker_name: [(post_id, content, author), ...]}
        suspected_posts_dict = {}  # {broker_name: [(post_id, content, author), ...]}

        # Patterns ×œ×©××•×ª ×—×‘×¨×•×ª
        company_patterns = [
            r'× ×“×œ["\']×Ÿ\s+(\w+)',  # × ×“×œ"×Ÿ X
            r'(\w+)\s+× ×›×¡×™×',      # X × ×›×¡×™×
            r'Real\s+Estate\s+(\w+)',  # Real Estate X
            r'××ª×•×•×š[×ª]?\s+(\w+)',  # ××ª×•×•×š X
        ]

        # Patterns ×œ×©××•×ª ×¤×¨×˜×™×™× ××ª×•×š ai_reason
        name_patterns = [
            r'×—×ª×™××” ×¢×¡×§×™×ª:\s*([×-×ª\sA-Za-z\'"×´]+?)(?:\s*[\+\)]|$)',  # "×—×ª×™××” ×¢×¡×§×™×ª: ×™×¨×“×Ÿ ×’××œ×™××œ"
            r'×—×ª×™××”:\s*([×-×ª\sA-Za-z\'"×´]+?)(?:\s*[\+\)]|$)',         # "×—×ª×™××”: × ×“×œ"×Ÿ JF"
            r'××ª×•×•×š\s*\(([×-×ª\sA-Za-z\'"×´]+?)\)',                    # "××ª×•×•×š (×©×)"
        ]

        # ×“×¤×•×¡×™× ×œ×”×ª×¢×œ××•×ª (×œ× ×œ×ª×¤×•×¡ ××•×ª×!)
        ignore_patterns = [
            r'××™×œ×ª ××¤×ª×—',
            r'×¡×•×›×Ÿ × ×“×œ',
            r'××¡×¤×¨ ×¨×™×©×™×•×Ÿ',
            r'×\.×¨\.',
        ]

        for post_id, content, author, reason, category in broker_posts:
            text_all = content + " " + (author or "") + " " + (reason or "")

            # 1. ×—×™×¤×•×© ×©××•×ª ×—×‘×¨×•×ª (patterns ×¨×’×™×œ×™×)
            for pattern in company_patterns:
                matches = re.findall(pattern, text_all, re.IGNORECASE)
                for match in matches:
                    # ×‘×“×•×§ ×× ×–×” ×œ× ×“×¤×•×¡ ×œ×”×ª×¢×œ××•×ª
                    if not any(ignore in match for ignore in ['××™×œ×ª', '××¤×ª×—']):
                        if category == 'SUSPECTED_BROKER':
                            suspected_names.append(match)
                            if match not in suspected_posts_dict:
                                suspected_posts_dict[match] = []
                            suspected_posts_dict[match].append((post_id, content, author))
                        else:
                            broker_names.append(match)
                            if match not in broker_posts_dict:
                                broker_posts_dict[match] = []
                            broker_posts_dict[match].append((post_id, content, author))

            # 2. ×—×™×¤×•×© ×©××•×ª ×¤×¨×˜×™×™× ××ª×•×š ai_reason
            if reason and '××™×œ×ª ××¤×ª×—' not in reason:
                for pattern in name_patterns:
                    matches = re.findall(pattern, reason, re.IGNORECASE)
                    for match in matches:
                        # × ×§×” ××ª ×”×©× (×”×¡×¨ ×¨×•×•×—×™× ××™×•×ª×¨×™×)
                        clean_name = match.strip()

                        # ×¡×™× ×•×Ÿ: ×“×œ×’ ×¢×œ ×“×¤×•×¡×™× ×œ×”×ª×¢×œ××•×ª
                        should_ignore = False
                        for ignore_pat in ignore_patterns:
                            if re.search(ignore_pat, clean_name, re.IGNORECASE):
                                should_ignore = True
                                break

                        if not should_ignore and clean_name and len(clean_name) > 3:
                            # ×›×œ ×”×¤×•×¡×˜×™× ×”××œ×” (BROKER ××• SUSPECTED_BROKER) ×”× ×—×©×•×“×™×
                            # ×›×™ ××™×Ÿ ×œ×”× ××¡×¤×¨ ×¨×™×©×™×•×Ÿ - ×¨×§ ×©× ×¤×¨×˜×™
                            suspected_names.append(clean_name)
                            if clean_name not in suspected_posts_dict:
                                suspected_posts_dict[clean_name] = []
                            suspected_posts_dict[clean_name].append((post_id, content, author))

            # 3. ×—×™×¤×•×© ××”-author ×× ×–×” BROKER ×•×•×“××™
            if category == 'BROKER' and author and '××™×œ×ª' not in author:
                # ×× ×”××•×˜×•×¨ ×”×•× ×©× (×œ× "Admin" ××• "Group")
                if len(author.split()) <= 3 and len(author.split()) >= 2:  # ×©× ××œ× (2-3 ××™×œ×™×)
                    try:
                        if author[0].isupper():
                            clean_author = author.strip()
                            suspected_names.append(clean_author)
                            if clean_author not in suspected_posts_dict:
                                suspected_posts_dict[clean_author] = []
                            suspected_posts_dict[clean_author].append((post_id, content, author))
                    except:
                        pass

        # ×¡×¤×•×¨ ×ª×“×™×¨×•×™×•×ª
        confirmed_counter = Counter(broker_names)
        suspected_counter = Counter(suspected_names)

        # ×¡× ×Ÿ ×¨×§ ×—×“×©×™× ×•×¤×•×¤×•×œ×¨×™×™× (××ª×•×•×›×™× ×•×•×“××™×™×)
        for name, count in confirmed_counter.most_common(10):
            clean_name = name.strip()
            clean_name_lower = clean_name.lower()

            # ×‘×“×•×§ ×× ×”×©× ×›×‘×¨ ×§×™×™×, ××• ×× ×”×•× ×—×œ×§ ××©× ××¨×•×š ×™×•×ª×¨ ×©×›×‘×¨ ×§×™×™×
            is_already_blocked = False

            # ×‘×“×™×§×” 1: ×”×× ×”×©× ×¢×¦××• ×§×™×™×?
            if clean_name_lower in existing_keywords:
                is_already_blocked = True

            # ×‘×“×™×§×” 2: ×”×× ×”×©× ×”×•× ×—×œ×§ ××©× ××¨×•×š ×™×•×ª×¨? (×œ××©×œ "××•×¨" ×‘"××•×¨ × ×›×¡×™×")
            if not is_already_blocked:
                for existing_kw in existing_keywords:
                    # ×‘×“×•×§ ×× ×”×©× ×©××¦×× ×• ×”×•× ×—×œ×§ ××‘×™×˜×•×™ ××¨×•×š ×™×•×ª×¨ ×©×›×‘×¨ ×§×™×™×
                    if clean_name_lower in existing_kw and len(clean_name_lower) < len(existing_kw):
                        is_already_blocked = True
                        break

            if count >= 2 and not is_already_blocked:
                posts_list = broker_posts_dict.get(name, [])
                self.recommendations['brokers'].append({
                    'term': clean_name,
                    'count': count,
                    'reason': f"××•×¤×™×¢ {count} ×¤×¢××™× ×‘×¤×•×¡×˜×™ ××ª×•×•×›×™× ×•×•×“××™×™×",
                    'type': 'confirmed',
                    'posts': posts_list[:3]  # ×¨×§ 3 ×¤×•×¡×˜×™× ×¨××©×•× ×™×
                })

        # ×—×©×•×“×™× (×’× ×× ×¨×§ 1 ×¤×¢×)
        for name, count in suspected_counter.most_common(10):
            clean_name = name.strip()
            clean_name_lower = clean_name.lower()

            # ×‘×“×•×§ ×× ×”×©× ×›×‘×¨ ×§×™×™×, ××• ×× ×”×•× ×—×œ×§ ××©× ××¨×•×š ×™×•×ª×¨ ×©×›×‘×¨ ×§×™×™×
            is_already_blocked = False

            # ×‘×“×™×§×” 1: ×”×× ×”×©× ×¢×¦××• ×§×™×™×?
            if clean_name_lower in existing_keywords:
                is_already_blocked = True

            # ×‘×“×™×§×” 2: ×”×× ×”×©× ×”×•× ×—×œ×§ ××©× ××¨×•×š ×™×•×ª×¨? (×œ××©×œ "××•×¨" ×‘"××•×¨ × ×›×¡×™×")
            if not is_already_blocked:
                for existing_kw in existing_keywords:
                    # ×‘×“×•×§ ×× ×”×©× ×©××¦×× ×• ×”×•× ×—×œ×§ ××‘×™×˜×•×™ ××¨×•×š ×™×•×ª×¨ ×©×›×‘×¨ ×§×™×™×
                    if clean_name_lower in existing_kw and len(clean_name_lower) < len(existing_kw):
                        is_already_blocked = True
                        break

            if not is_already_blocked:
                posts_list = suspected_posts_dict.get(name, [])
                self.recommendations['brokers'].append({
                    'term': clean_name,
                    'count': count,
                    'reason': f"×—×©×•×“ ×œ××ª×•×•×š ({count} ×¤×•×¡×˜×™×)",
                    'type': 'suspected',
                    'posts': posts_list[:3]  # ×¨×§ 3 ×¤×•×¡×˜×™× ×¨××©×•× ×™×
                })

        # ×”×“×¤×¡×”
        if self.recommendations['brokers']:
            confirmed = [b for b in self.recommendations['brokers'] if b.get('type') == 'confirmed']
            suspected = [b for b in self.recommendations['brokers'] if b.get('type') == 'suspected']

            if confirmed:
                print(f"  ğŸ”´ × ××¦××• {len(confirmed)} ××ª×•×•×›×™× ×•×•×“××™×™×:")
                for item in confirmed[:5]:
                    print(f"     âš ï¸ '{item['term']}' - {item['count']} ×¤×•×¡×˜×™×")
                    # ×”×¦×’ ×ª×¦×•×’×” ××§×“×™××” ×©×œ ×”×¤×•×¡×˜×™×
                    for i, (post_id, content, author) in enumerate(item.get('posts', [])[:2], 1):
                        preview = content[:80].replace('\n', ' ')
                        if len(content) > 80:
                            preview += "..."
                        print(f"        ğŸ“„ ×¤×•×¡×˜ #{i}: {preview}")
                        if author:
                            print(f"           ğŸ‘¤ ××—×‘×¨: {author}")

            if suspected:
                print(f"  ğŸŸ¡ × ××¦××• {len(suspected)} ××ª×•×•×›×™× ×—×©×•×“×™×:")
                for item in suspected[:5]:
                    print(f"     ğŸ” '{item['term']}' - {item['count']} ×¤×•×¡×˜×™× (×—×©×“)")
                    # ×”×¦×’ ×ª×¦×•×’×” ××§×“×™××” ×©×œ ×”×¤×•×¡×˜×™×
                    for i, (post_id, content, author) in enumerate(item.get('posts', [])[:2], 1):
                        preview = content[:80].replace('\n', ' ')
                        if len(content) > 80:
                            preview += "..."
                        print(f"        ğŸ“„ ×¤×•×¡×˜ #{i}: {preview}")
                        if author:
                            print(f"           ğŸ‘¤ ××—×‘×¨: {author}")
        else:
            print("  âœ… ×œ× × ××¦××• ××ª×•×•×›×™× ×—×“×©×™×")

    def _find_publishers_for_brokers(self):
        """××•×¦× ××¤×¨×¡××™× ×©×¢×•×‘×“×™× ×¢×‘×•×¨ ××ª×•×•×›×™× - ×’× ×¢× 1 ×¤×•×¡×˜!"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()

            # ×©×œ×•×£ ××ª ×›×œ ×”×¤×•×¡×˜×™× (×œ× ×¨×§ BROKER/SUSPECTED_BROKER)
            cursor.execute("""
                SELECT post_id, content, author, category
                FROM posts
                WHERE author IS NOT NULL
                AND author != ''
                LIMIT 200
            """)

            all_posts = cursor.fetchall()

        # ×˜×¢×Ÿ broker_keywords ×§×™×™××™×
        with open(self.config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        broker_keywords = [kw.lower() for kw in config['search_settings']['search_settings']['broker_keywords']]
        existing_keywords = set(broker_keywords)

        # ××™×œ×•×Ÿ: author -> [(post_id, content, broker_keywords_found), ...]
        publishers_dict = {}

        for post_id, content, author, category in all_posts:
            content_lower = content.lower()

            # ×‘×“×•×§ ×× ×”×ª×•×›×Ÿ ××›×™×œ broker_keywords
            found_keywords = []
            for kw in broker_keywords:
                if kw in content_lower:
                    found_keywords.append(kw)

            # ×× ××¦×× ×• broker_keywords ×‘×¤×•×¡×˜
            if found_keywords:
                author_lower = author.lower()

                # ×‘×“×•×§ ×× ×”-author ×¢×¦××• ×›×‘×¨ ×‘-broker_keywords (××– ×œ× ×¦×¨×™×š ×œ×”××œ×™×¥)
                if author_lower in existing_keywords:
                    continue

                # ×”×•×¡×£ ××ª ×”××¤×¨×¡× ×œ×¨×©×™××”
                if author not in publishers_dict:
                    publishers_dict[author] = []

                publishers_dict[author].append({
                    'post_id': post_id,
                    'content': content,
                    'broker_keywords': found_keywords
                })

        # ×¢×›×©×™×• ×™×© ×œ× ×• ×¨×©×™××” ×©×œ authors ×©××¤×¨×¡××™× ×¤×•×¡×˜×™× ×¢× broker_keywords
        # ×”××œ×¥ ×œ×—×¡×•× ××•×ª× (×’× ×× ×™×© ×œ×”× ×¨×§ 1 ×¤×•×¡×˜!)
        for author, posts in publishers_dict.items():
            # ×¨×§ ×× ×–×” ×©× ×¤×¨×˜×™ (2-3 ××™×œ×™×, ××ª×—×™×œ ×‘××•×ª ×’×“×•×œ×”)
            if len(author.split()) >= 2 and len(author.split()) <= 3:
                try:
                    if author[0].isupper():
                        self.recommendations['publishers_for_brokers'].append({
                            'author': author,
                            'count': len(posts),
                            'broker_keywords': posts[0]['broker_keywords'],  # ×”××™×œ×™× ×©× ××¦××•
                            'posts': posts[:2]  # ×¢×“ 2 ×¤×•×¡×˜×™× ×œ×ª×¦×•×’×”
                        })
                except:
                    pass

        # ×”×“×¤×¡×”
        if self.recommendations['publishers_for_brokers']:
            print(f"  ğŸŸ  × ××¦××• {len(self.recommendations['publishers_for_brokers'])} ××¤×¨×¡××™× ×©×¢×•×‘×“×™× ×¢×‘×•×¨ ××ª×•×•×›×™×:")
            for item in self.recommendations['publishers_for_brokers'][:5]:
                broker_kw_str = ', '.join(item['broker_keywords'][:2])
                print(f"     ğŸ‘¤ '{item['author']}' - {item['count']} ×¤×•×¡×˜×™× (××¤×¨×¡× ×¢×‘×•×¨: {broker_kw_str})")
                # ×”×¦×’ ×ª×¦×•×’×” ××§×“×™××” ×©×œ ×”×¤×•×¡×˜×™×
                for i, post in enumerate(item['posts'][:2], 1):
                    preview = post['content'][:80].replace('\n', ' ')
                    if len(post['content']) > 80:
                        preview += "..."
                    print(f"        ğŸ“„ ×¤×•×¡×˜ #{i}: {preview}")
                    print(f"           ğŸ’¡ ××›×™×œ: {', '.join(post['broker_keywords'][:2])}")
            print(f"   ğŸ’¡ ×”××œ×¦×”: ×”×•×¡×£ ×œ-broker_keywords (××¤×¨×¡××™× ×©×¢×•×‘×“×™× ×¢×‘×•×¨ ××ª×•×•×›×™×)")
        else:
            print("  âœ… ×œ× × ××¦××• ××¤×¨×¡××™× ×—×“×©×™×")

    def _find_settlements(self):
        """××•×¦× ×™×™×©×•×‘×™× ×©×¢×‘×¨×•"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()

            # ×¤×•×¡×˜×™× ×¨×œ×•×•× ×˜×™×™× ×¢× ××™×œ×•×ª ××¤×ª×— ×—×©×•×“×•×ª
            cursor.execute("""
                SELECT content, city, location
                FROM posts
                WHERE is_relevant = 1
                AND (
                    content LIKE '%××•×©×‘%' OR
                    content LIKE '%×™×™×©×•×‘%' OR
                    content LIKE '%×”×ª× ×—×œ×•×ª%' OR
                    content LIKE '%× ×•×£%' OR
                    content LIKE '%×›×¤×¨%'
                )
                LIMIT 50
            """)

            posts = cursor.fetchall()

        # ×—×œ×¥ ×©××•×ª ×™×™×©×•×‘×™×
        settlement_pattern = r'(?:××•×©×‘|×™×™×©×•×‘|×”×ª× ×—×œ×•×ª|×›×¤×¨)\s+([×-×ª\s]{2,20})'

        settlements = []
        for content, city, location in posts:
            text = content + " " + (city or "") + " " + (location or "")
            matches = re.findall(settlement_pattern, text)
            settlements.extend([m.strip() for m in matches])

        # ×¡×¤×•×¨
        counter = Counter(settlements)

        for name, count in counter.most_common(10):
            if count >= 2:
                self.recommendations['settlements'].append({
                    'term': name,
                    'count': count,
                    'reason': f"×™×™×©×•×‘ ×§×˜×Ÿ - {count} ×¤×•×¡×˜×™×"
                })

        # ×”×“×¤×¡×”
        if self.recommendations['settlements']:
            print(f"  ğŸ’¡ × ××¦××• {len(self.recommendations['settlements'])} ×™×™×©×•×‘×™×:")
            for item in self.recommendations['settlements'][:5]:
                print(f"     ğŸ˜ï¸ '{item['term']}' - {item['count']} ×¤×•×¡×˜×™×")
        else:
            print("  âœ… ×œ× × ××¦××• ×™×™×©×•×‘×™× ×—×“×©×™×")

    def _find_blacklist_terms(self):
        """××•×¦× ×‘×™×˜×•×™×™× ×—×“×©×™× ×œblacklist"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()

            # ×¤×•×¡×˜×™× ×©×¢×‘×¨×• ××‘×œ ××›×™×œ×™× ××™×œ×•×ª ×—×™×¤×•×©
            cursor.execute("""
                SELECT content
                FROM posts
                WHERE is_relevant = 1
                AND (
                    content LIKE '%××—×¤×©%' OR
                    content LIKE '%××—×¤×©×ª%' OR
                    content LIKE '%×“×¨×•×©%' OR
                    content LIKE '%×–×§×•×§%'
                )
                LIMIT 100
            """)

            posts = cursor.fetchall()

        # ×˜×¢×Ÿ blacklist ×§×™×™××ª
        with open(self.config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        existing_blacklist = set(kw.lower() for kw in config['search_settings']['search_settings']['blacklist'])

        # ×“×¤×•×¡×™×
        patterns = [
            r'××—×¤×©[×ª]?\s+×—×“×¨',
            r'×“×¨×•×©[×”]?\s+××§×•×',
            r'×–×§×•×§[×”]?\s+×œ',
            r'××—×¤×©[×ª]?\s+×©×•×ª×£',
        ]

        terms = []
        for (content,) in posts:
            for pattern in patterns:
                if re.search(pattern, content, re.IGNORECASE):
                    match = re.search(pattern, content, re.IGNORECASE)
                    terms.append(match.group(0))

        # ×¡×¤×•×¨
        counter = Counter(terms)

        for term, count in counter.most_common(10):
            if count >= 3 and term.lower() not in existing_blacklist:
                self.recommendations['blacklist'].append({
                    'term': term,
                    'count': count,
                    'reason': f"×‘×™×˜×•×™ ×—×™×¤×•×© - {count} ×¤×•×¡×˜×™×"
                })

        # ×”×“×¤×¡×”
        if self.recommendations['blacklist']:
            print(f"  ğŸ’¡ × ××¦××• {len(self.recommendations['blacklist'])} ×‘×™×˜×•×™×™×:")
            for item in self.recommendations['blacklist'][:5]:
                print(f"     ğŸš« '{item['term']}' - {item['count']} ×¤×•×¡×˜×™×")
        else:
            print("  âœ… ×œ× × ××¦××• ×‘×™×˜×•×™×™× ×—×“×©×™×")

    def _find_repeat_posters(self):
        """××–×”×” ××©×ª××©×™× ×©××¤×¨×¡××™× ×”×¨×‘×” ×¤×¢××™× - ××•×œ×™ ××ª×•×•×›×™× ×¡××•×™×™×"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()

            # ×¡×¤×•×¨ ×¤×•×¡×˜×™× ×œ×¤×™ author (×¨×§ ×¤×•×¡×˜×™× ×¨×œ×•×•× ×˜×™×™× ×©×œ× ×¡×•×× ×• ×›××ª×•×•×›×™×)
            cursor.execute("""
                SELECT author, COUNT(*) as post_count
                FROM posts
                WHERE author IS NOT NULL
                AND author != ''
                AND is_relevant = 1
                AND is_broker = 0
                GROUP BY author
                HAVING post_count >= 5
                ORDER BY post_count DESC
                LIMIT 20
            """)

            repeat_posters = cursor.fetchall()

        # ×‘× ×” ×¨×©×™××ª ×”××œ×¦×•×ª
        if 'repeat_posters' not in self.recommendations:
            self.recommendations['repeat_posters'] = []

        for author, count in repeat_posters:
            self.recommendations['repeat_posters'].append({
                'author': author,
                'count': count,
                'reason': f"×¤×¨×¡× {count} ×¤×•×¡×˜×™× - ××•×œ×™ ××ª×•×•×š ×¡××•×™"
            })

        # ×”×“×¤×¡×”
        if self.recommendations['repeat_posters']:
            print(f"  âš ï¸ × ××¦××• {len(self.recommendations['repeat_posters'])} ××©×ª××©×™× ×—×©×•×“×™×:")
            for item in self.recommendations['repeat_posters'][:5]:
                print(f"     ğŸ” '{item['author']}' - {item['count']} ×¤×•×¡×˜×™×")
            print(f"   ğŸ’¡ ×”××œ×¦×”: ×‘×“×•×§ ×™×“× ×™×ª - ×× ×–×” ××ª×•×•×š ×”×•×¡×£ ×œbroker_keywords")
        else:
            print("  âœ… ×œ× × ××¦××• ××©×ª××©×™× ×—×©×•×“×™×")

    def _find_misclassified_posts(self):
        """××–×”×” ×¤×•×¡×˜×™× ×©××•×œ×™ ×¡×•×•×’×• ×œ× × ×›×•×Ÿ"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()

            # ×˜×¢×Ÿ broker_keywords
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            broker_keywords = [kw.lower() for kw in config['search_settings']['search_settings']['broker_keywords']]
            cities = [city.lower() for city in config['search_settings']['cities']]

            # 1. ×¤×•×¡×˜×™× ×©×¡×•×× ×• RELEVANT ××‘×œ ×™×© ×‘×”× ××™×œ×•×ª ××¤×ª×— ×©×œ ××ª×•×•×›×™×
            print("     ğŸ” ×‘×•×“×§ RELEVANT ×¢× ××™×œ×•×ª ××ª×•×•×š...")
            cursor.execute("""
                SELECT post_id, content, author, city
                FROM posts
                WHERE is_relevant = 1
                AND category = 'RELEVANT'
                LIMIT 100
            """)

            relevant_posts = cursor.fetchall()
            for post_id, content, author, city in relevant_posts:
                text = (content + " " + (author or "")).lower()

                # ×“×¤×•×¡×™ ×©×œ×™×œ×” (×›××• ×‘-listener.py)
                negation_patterns = [
                    r'\b×œ×œ×\s+',      # "×œ×œ× ×ª×™×•×•×š"
                    r'\b×‘×œ×™\s+',      # "×‘×œ×™ ×ª×™×•×•×š"
                    r'\b×œ×\s+',       # "×œ× ×ª×™×•×•×š"
                    r'\b×œ×œ×\s+×“××™\s+', # "×œ×œ× ×“××™ ×ª×™×•×•×š"
                    r'\b×‘×œ×™\s+×“××™\s+', # "×‘×œ×™ ×“××™ ×ª×™×•×•×š"
                ]

                found_keywords = []
                for kw in broker_keywords:
                    if kw in text:
                        # ×‘×“×•×§ ×× ×™×© ×©×œ×™×œ×” ×œ×¤× ×™ ×”××™×œ×”
                        is_negated = False
                        for negation in negation_patterns:
                            pattern = negation + re.escape(kw)
                            if re.search(pattern, text):
                                is_negated = True
                                break

                        # ×¨×§ ×× ××™×Ÿ ×©×œ×™×œ×” - ×”×•×¡×£ ×œ×¨×©×™××”
                        if not is_negated:
                            found_keywords.append(kw)

                if found_keywords:
                    self.recommendations['misclassified'].append({
                        'post_id': post_id,
                        'type': 'RELEVANT_WITH_BROKER_KEYWORDS',
                        'content_preview': content[:100] + "...",
                        'city': city,
                        'reason': f"××›×™×œ ××™×œ×•×ª ××ª×•×•×š: {', '.join(found_keywords[:3])}"
                    })

            # 2. ×¤×•×¡×˜×™× ×©×¡×•×× ×• NON_URBAN ××‘×œ ×”× ××¢×™×¨ ×¨×œ×•×•× ×˜×™×ª
            print("     ğŸ” ×‘×•×“×§ NON_URBAN ××¢×™×¨ ×¨×œ×•×•× ×˜×™×ª...")
            cursor.execute("""
                SELECT post_id, content, city, location
                FROM posts
                WHERE category = 'NON_URBAN'
                LIMIT 100
            """)

            non_urban_posts = cursor.fetchall()
            for post_id, content, city, location in non_urban_posts:
                city_lower = (city or "").lower()
                if city_lower in cities:
                    self.recommendations['misclassified'].append({
                        'post_id': post_id,
                        'type': 'NON_URBAN_BUT_RELEVANT_CITY',
                        'content_preview': content[:100] + "...",
                        'city': city,
                        'reason': f"×¢×™×¨ '{city}' ×¨×œ×•×•× ×˜×™×ª ××‘×œ ×¡×•××Ÿ NON_URBAN"
                    })

            # 3. ×¤×•×¡×˜×™× ×©×¡×•×× ×• BROKER ××‘×œ ××™×Ÿ ×‘×”× ×¡×™×× ×™ ×ª×™×•×•×š ×‘×¨×•×¨×™×
            print("     ğŸ” ×‘×•×“×§ BROKER ×œ×œ× ×¡×™×× ×™ ×ª×™×•×•×š...")
            cursor.execute("""
                SELECT post_id, content, author, ai_reason
                FROM posts
                WHERE is_broker = 1 OR category = 'BROKER'
                LIMIT 50
            """)

            broker_posts = cursor.fetchall()
            for post_id, content, author, ai_reason in broker_posts:
                text = (content + " " + (author or "")).lower()

                # ×‘×“×•×§ ×× ×™×© ×¡×™×× ×™× ×‘×¨×•×¨×™×
                has_broker_signs = any([
                    kw in text for kw in broker_keywords
                ]) or any([
                    word in text for word in ['××ª×•×•×š', '×ª×™×•×•×š', '× ×“×œ×Ÿ', '× ×›×¡×™×', 'real estate']
                ])

                if not has_broker_signs:
                    self.recommendations['misclassified'].append({
                        'post_id': post_id,
                        'type': 'BROKER_WITHOUT_CLEAR_SIGNS',
                        'content_preview': content[:100] + "...",
                        'city': None,
                        'reason': f"××™×Ÿ ×¡×™×× ×™ ×ª×™×•×•×š ×‘×¨×•×¨×™×. AI ×××¨: {ai_reason[:50] if ai_reason else 'N/A'}"
                    })

        # ×”×“×¤×¡×”
        if self.recommendations['misclassified']:
            print(f"  âš ï¸ × ××¦××• {len(self.recommendations['misclassified'])} ×¤×•×¡×˜×™× ×—×©×•×“×™×:")
            for item in self.recommendations['misclassified'][:5]:
                print(f"     âš ï¸ Post #{item['post_id']} - {item['type']}")
                print(f"        {item['reason']}")
        else:
            print("  âœ… ×œ× × ××¦××• ×¤×•×¡×˜×™× ×—×©×•×“×™×")

    def _print_recommendations(self):
        """×¡×™×›×•× ×”××œ×¦×•×ª"""
        total = sum(len(v) for v in self.recommendations.values())

        if total == 0:
            print("âœ¨ ××•×©×œ×! ×œ× × ××¦××• ×©×™×¤×•×¨×™× × ×“×¨×©×™×")
            print("   ×”××¢×¨×›×ª ××›×•×™×œ×ª ×”×™×˜×‘ ğŸ¯")
            return

        print(f"ğŸ’¡ ×¡×”\"×› {total} ×”××œ×¦×•×ª ×œ×©×™×¤×•×¨:\n")

        if self.recommendations['brokers']:
            print(f"1ï¸âƒ£ ××ª×•×•×›×™× ×—×“×©×™× ({len(self.recommendations['brokers'])}):")
            for item in self.recommendations['brokers'][:5]:
                broker_type = "ğŸ”´ ×•×•×“××™" if item.get('type') == 'confirmed' else "ğŸŸ¡ ×—×©×•×“"
                print(f"   {broker_type} \"{item['term']}\" - {item['count']} ×¤×•×¡×˜×™×")
                # ×”×¦×’ ×ª×¦×•×’×” ××§×“×™××” ×©×œ ×”×¤×•×¡×˜×™×
                for i, (post_id, content, author) in enumerate(item.get('posts', [])[:2], 1):
                    preview = content[:80].replace('\n', ' ')
                    if len(content) > 80:
                        preview += "..."
                    print(f"      ğŸ“„ ×¤×•×¡×˜ #{i}: {preview}")
                    if author:
                        print(f"         ğŸ‘¤ ××—×‘×¨: {author}")
            print(f"   ğŸ’¡ ×”××œ×¦×”: ×”×•×¡×£ ×œ-broker_keywords\n")

        if self.recommendations['publishers_for_brokers']:
            print(f"2ï¸âƒ£ ××¤×¨×¡××™× ×©×¢×•×‘×“×™× ×¢×‘×•×¨ ××ª×•×•×›×™× ({len(self.recommendations['publishers_for_brokers'])}):")
            for item in self.recommendations['publishers_for_brokers'][:5]:
                broker_kw_str = ', '.join(item['broker_keywords'][:2])
                print(f"   ğŸŸ  \"{item['author']}\" - {item['count']} ×¤×•×¡×˜×™× (××¤×¨×¡× ×¢×‘×•×¨: {broker_kw_str})")
                # ×”×¦×’ ×ª×¦×•×’×” ××§×“×™××” ×©×œ ×”×¤×•×¡×˜×™×
                for i, post in enumerate(item['posts'][:2], 1):
                    preview = post['content'][:80].replace('\n', ' ')
                    if len(post['content']) > 80:
                        preview += "..."
                    print(f"      ğŸ“„ ×¤×•×¡×˜ #{i}: {preview}")
                    print(f"         ğŸ’¡ ××›×™×œ: {', '.join(post['broker_keywords'][:2])}")
            print(f"   ğŸ’¡ ×”××œ×¦×”: ×”×•×¡×£ ×œ-broker_keywords (××¤×¨×¡××™× ×¢×‘×•×¨ ××ª×•×•×›×™×)\n")

        if self.recommendations['settlements']:
            print(f"3ï¸âƒ£ ×™×™×©×•×‘×™× ({len(self.recommendations['settlements'])}):")
            for item in self.recommendations['settlements'][:5]:
                print(f"   ğŸ˜ï¸ \"{item['term']}\" - {item['count']} ×¤×•×¡×˜×™×")
            print(f"   ğŸ’¡ ×”××œ×¦×”: ×”×•×¡×£ ×œ-NON_URBAN (ai_agents.py)\n")

        if self.recommendations['blacklist']:
            print(f"4ï¸âƒ£ Blacklist ({len(self.recommendations['blacklist'])}):")
            for item in self.recommendations['blacklist'][:5]:
                print(f"   ğŸš« \"{item['term']}\" - {item['count']} ×¤×•×¡×˜×™×")
            print(f"   ğŸ’¡ ×”××œ×¦×”: ×”×•×¡×£ ×œ-blacklist\n")

        if self.recommendations.get('repeat_posters'):
            print(f"5ï¸âƒ£ ××©×ª××©×™× ×—×•×–×¨×™× ({len(self.recommendations['repeat_posters'])}):")
            for item in self.recommendations['repeat_posters'][:5]:
                print(f"   ğŸ” \"{item['author']}\" - {item['count']} ×¤×•×¡×˜×™×")
            print(f"   ğŸ’¡ ×”××œ×¦×”: ×‘×“×•×§ ×™×“× ×™×ª - ×× ×–×” ××ª×•×•×š ×”×•×¡×£ ××ª ×©××• ×œbroker_keywords\n")

        if self.recommendations['misclassified']:
            print(f"6ï¸âƒ£ ×¤×•×¡×˜×™× ×—×©×•×“×™× ({len(self.recommendations['misclassified'])}):")
            for item in self.recommendations['misclassified'][:5]:
                print(f"   âš ï¸ Post #{item['post_id']} - {item['type']}")
                print(f"      {item['reason']}")
                print(f"      ×ª×¦×•×’×”: {item['content_preview']}")
            print(f"   ğŸ’¡ ×”××œ×¦×”: ×‘×“×•×§ ×™×“× ×™×ª - ××•×œ×™ ×¦×¨×™×š ×œ×¢×“×›×Ÿ ×”× ×—×™×•×ª AI\n")

        print("=" * 70)
        print("ğŸ’¡ ×”×¨×¥ ×¢× --apply ×›×“×™ ×œ×™×™×©×, ××• --interactive ×œ×‘×—×•×¨")
        print("=" * 70)

    def _create_backup(self, file_path):
        """×™×•×¦×¨ backup ×©×œ ×§×•×‘×¥"""
        if not os.path.exists(file_path):
            return None

        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        backup_path = f"{file_path}.backup.{timestamp}"
        shutil.copy2(file_path, backup_path)
        return backup_path

    def _apply_broker_keywords(self):
        """××¢×“×›×Ÿ broker_keywords ×‘config.json"""
        if not self.recommendations['brokers']:
            return 0

        # ×˜×¢×Ÿ config
        with open(self.config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)

        # ×”×•×¡×£ ××™×œ×•×ª ××¤×ª×— ×—×“×©×•×ª
        existing = set(kw.lower() for kw in config['search_settings']['search_settings']['broker_keywords'])
        added = 0

        for item in self.recommendations['brokers']:
            term = item['term']
            if term.lower() not in existing:
                config['search_settings']['search_settings']['broker_keywords'].append(term)
                added += 1
                print(f"   âœ… ×”×•×¡×¤×ª×™: \"{term}\"")

        # ×©××•×¨
        with open(self.config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)

        return added

    def _apply_blacklist(self):
        """××¢×“×›×Ÿ blacklist ×‘config.json"""
        if not self.recommendations['blacklist']:
            return 0

        # ×˜×¢×Ÿ config
        with open(self.config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)

        # ×”×•×¡×£ ×‘×™×˜×•×™×™× ×—×“×©×™×
        existing = set(kw.lower() for kw in config['search_settings']['search_settings']['blacklist'])
        added = 0

        for item in self.recommendations['blacklist']:
            term = item['term']
            if term.lower() not in existing:
                config['search_settings']['search_settings']['blacklist'].append(term)
                added += 1
                print(f"   âœ… ×”×•×¡×¤×ª×™: \"{term}\"")

        # ×©××•×¨
        with open(self.config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)

        return added

    def _apply_settlements(self):
        """××¢×“×›×Ÿ NON_URBAN ×‘ai_agents.py"""
        if not self.recommendations['settlements']:
            return 0

        ai_agents_path = "ai_agents.py"
        if not os.path.exists(ai_agents_path):
            print("   âš ï¸ ai_agents.py ×œ× × ××¦× - ×“×œ×’ ×¢×œ ×™×™×©×•×‘×™×")
            return 0

        # ×§×¨× ×§×•×‘×¥
        with open(ai_agents_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # ××¦× ××ª ×”×¡×¢×™×£ ×©×œ NON_URBAN
        # × ×•×¡×™×£ ××ª ×”×™×™×©×•×‘×™× ×”×—×“×©×™× ×œ×¨×©×™××ª ×”×“×•×’×××•×ª
        settlements_to_add = [item['term'] for item in self.recommendations['settlements']]

        # ×—×¤×© ××ª ×”×©×•×¨×” "- \"× ×•×¤×™×\" (×™×™×©×•×‘ ×‘×‘×™×ª ×©××©)"
        pattern = r'(\s+- "× ×•×¤×™×" \(×™×™×©×•×‘ ×‘×‘×™×ª ×©××©\) â†’ NON_URBAN âš ï¸ ×—×©×•×‘!)'

        if re.search(pattern, content):
            # ×”×•×¡×£ ×™×™×©×•×‘×™× ×—×“×©×™× ××—×¨×™ "× ×•×¤×™×"
            new_lines = []
            for settlement in settlements_to_add[:5]:  # ××’×‘×™×œ ×œ-5 ×™×™×©×•×‘×™×
                new_lines.append(f'  - "{settlement}" â†’ NON_URBAN')

            replacement = r'\1\n' + '\n'.join(new_lines)
            content = re.sub(pattern, replacement, content)

            # ×©××•×¨
            with open(ai_agents_path, 'w', encoding='utf-8') as f:
                f.write(content)

            for settlement in settlements_to_add[:5]:
                print(f"   âœ… ×”×•×¡×¤×ª×™: \"{settlement}\"")

            return len(settlements_to_add[:5])
        else:
            print("   âš ï¸ ×œ× ××¦××ª×™ ××ª ×”×¡×¢×™×£ NON_URBAN - ×¢×“×›×Ÿ ×™×“× ×™×ª")
            return 0

    def apply_all(self, interactive=False):
        """××™×™×©× ××ª ×›×œ ×”×”××œ×¦×•×ª"""
        total = sum(len(v) for v in self.recommendations.values())

        if total == 0:
            print("âœ¨ ××™×Ÿ ×”××œ×¦×•×ª ×œ×™×™×©×•×!")
            return

        print("\n" + "=" * 70)
        print("âš¡ ××ª×—×™×œ ×™×™×©×•× ×©×™× ×•×™×™×...")
        print("=" * 70 + "\n")

        # Backup
        print("ğŸ“¦ ×™×•×¦×¨ Backups...")
        config_backup = self._create_backup(self.config_path)
        ai_agents_backup = self._create_backup("ai_agents.py")

        if config_backup:
            print(f"   âœ… {config_backup}")
        if ai_agents_backup:
            print(f"   âœ… {ai_agents_backup}")

        print()

        # ×™×™×©×•×
        total_applied = 0

        # ××ª×•×•×›×™×
        if self.recommendations['brokers']:
            if interactive:
                print(f"\nğŸ” × ××¦××• {len(self.recommendations['brokers'])} ××ª×•×•×›×™× ×—×“×©×™×:")
                print("   (×›×œ ××ª×•×•×š ×™×•×¦×’ ×‘× ×¤×¨×“ - ×ª×‘×—×¨ ×”×× ×œ×”×•×¡×™×£)\n")

                # ×©××œ×” ×œ×’×‘×™ ×›×œ ××ª×•×•×š ×‘× ×¤×¨×“
                approved_brokers = []
                for broker in self.recommendations['brokers']:
                    term = broker['term']
                    count = broker['count']
                    broker_type = "ğŸ”´ ×•×•×“××™" if broker.get('type') == 'confirmed' else "ğŸŸ¡ ×—×©×•×“"

                    print(f"\n   {broker_type}: '{term}' ({count} ×¤×•×¡×˜×™×)")
                    print(f"   ×¡×™×‘×”: {broker['reason']}")
                    response = input(f"   ğŸ’¡ ×œ×”×•×¡×™×£ '{term}' ×œ-broker_keywords? (y/n): ")

                    if response.lower() == 'y':
                        approved_brokers.append(broker)
                        print(f"   âœ… '{term}' ×™×ª×•×•×¡×£")
                    else:
                        print(f"   â­ï¸ ×“×™×œ×’×ª×™ ×¢×œ '{term}'")

                # ×”×•×¡×£ ×¨×§ ××ª ×”×××•×©×¨×™×
                if approved_brokers:
                    self.recommendations['brokers'] = approved_brokers
                    print("\nğŸ” ××•×¡×™×£ broker_keywords ×©× ×‘×—×¨×•...")
                    added = self._apply_broker_keywords()
                    total_applied += added
                else:
                    print("\n   â­ï¸ ×œ× × ×‘×—×¨×• ××ª×•×•×›×™× ×œ×”×•×¡×¤×”")
                    self.recommendations['brokers'] = []
            else:
                print("\nğŸ” ××•×¡×™×£ broker_keywords...")
                added = self._apply_broker_keywords()
                total_applied += added

        # ××¤×¨×¡××™× ×©×¢×•×‘×“×™× ×¢×‘×•×¨ ××ª×•×•×›×™×
        if self.recommendations['publishers_for_brokers']:
            if interactive:
                print(f"\nğŸ‘¤ × ××¦××• {len(self.recommendations['publishers_for_brokers'])} ××¤×¨×¡××™× ×©×¢×•×‘×“×™× ×¢×‘×•×¨ ××ª×•×•×›×™×:")
                print("   (×›×œ ××¤×¨×¡× ×™×•×¦×’ ×‘× ×¤×¨×“ - ×ª×‘×—×¨ ×”×× ×œ×”×•×¡×™×£)\n")

                # ×©××œ×” ×œ×’×‘×™ ×›×œ ××¤×¨×¡× ×‘× ×¤×¨×“
                approved_publishers = []
                for publisher in self.recommendations['publishers_for_brokers']:
                    author = publisher['author']
                    count = publisher['count']
                    broker_kw = ', '.join(publisher['broker_keywords'][:2])

                    print(f"\n   ğŸŸ  '{author}' ({count} ×¤×•×¡×˜×™×)")
                    print(f"   ××¤×¨×¡× ×¢×‘×•×¨: {broker_kw}")

                    # ×”×¦×’ ×¤×•×¡×˜ ××—×“ ×œ×“×•×’××”
                    if publisher['posts']:
                        preview = publisher['posts'][0]['content'][:80].replace('\n', ' ')
                        if len(publisher['posts'][0]['content']) > 80:
                            preview += "..."
                        print(f"   ×“×•×’××”: {preview}")

                    response = input(f"   ğŸ’¡ ×œ×”×•×¡×™×£ '{author}' ×œ-broker_keywords? (y/n): ")

                    if response.lower() == 'y':
                        approved_publishers.append(publisher)
                        print(f"   âœ… '{author}' ×™×ª×•×•×¡×£")
                    else:
                        print(f"   â­ï¸ ×“×™×œ×’×ª×™ ×¢×œ '{author}'")

                # ×”×•×¡×£ ×¨×§ ××ª ×”×××•×©×¨×™×
                if approved_publishers:
                    # ×”××¨ ××ª ×”××¤×¨×¡××™× ×œ×¤×•×¨××˜ ×©××ª××™× ×œ-_apply_broker_keywords
                    for publisher in approved_publishers:
                        self.recommendations['brokers'].append({
                            'term': publisher['author'],
                            'count': publisher['count'],
                            'reason': f"××¤×¨×¡× ×¢×‘×•×¨ {', '.join(publisher['broker_keywords'][:2])}",
                            'type': 'publisher'
                        })

                    print("\nğŸ‘¤ ××•×¡×™×£ ××¤×¨×¡××™× ×©× ×‘×—×¨×•...")
                    added = self._apply_broker_keywords()
                    total_applied += added

                    # × ×§×” ××ª brokers ×›×“×™ ×œ× ×œ×¡×¤×•×¨ ×¤×¢××™×™×
                    self.recommendations['brokers'] = [b for b in self.recommendations['brokers'] if b.get('type') != 'publisher']
                else:
                    print("\n   â­ï¸ ×œ× × ×‘×—×¨×• ××¤×¨×¡××™× ×œ×”×•×¡×¤×”")
            else:
                # ××¦×‘ ××•×˜×•××˜×™ - ×”×•×¡×£ ××ª ×›×•×œ×
                for publisher in self.recommendations['publishers_for_brokers']:
                    self.recommendations['brokers'].append({
                        'term': publisher['author'],
                        'count': publisher['count'],
                        'reason': f"××¤×¨×¡× ×¢×‘×•×¨ {', '.join(publisher['broker_keywords'][:2])}",
                        'type': 'publisher'
                    })

                print("\nğŸ‘¤ ××•×¡×™×£ ××¤×¨×¡××™×...")
                added = self._apply_broker_keywords()
                total_applied += added

                # × ×§×” ××ª brokers ×›×“×™ ×œ× ×œ×¡×¤×•×¨ ×¤×¢××™×™×
                self.recommendations['brokers'] = [b for b in self.recommendations['brokers'] if b.get('type') != 'publisher']

        # Blacklist
        if self.recommendations['blacklist']:
            if interactive:
                response = input(f"\nâ“ ×œ×”×•×¡×™×£ {len(self.recommendations['blacklist'])} ×‘×™×˜×•×™×™× ×œ-blacklist? (y/n): ")
                if response.lower() != 'y':
                    print("   â­ï¸ ×“×™×œ×’×ª×™ ×¢×œ blacklist")
                else:
                    print("\nğŸš« ××•×¡×™×£ ×œ-blacklist...")
                    added = self._apply_blacklist()
                    total_applied += added
            else:
                print("\nğŸš« ××•×¡×™×£ ×œ-blacklist...")
                added = self._apply_blacklist()
                total_applied += added

        # ×™×™×©×•×‘×™×
        if self.recommendations['settlements']:
            if interactive:
                response = input(f"\nâ“ ×œ×”×•×¡×™×£ {len(self.recommendations['settlements'])} ×™×™×©×•×‘×™× ×œ-NON_URBAN? (y/n): ")
                if response.lower() != 'y':
                    print("   â­ï¸ ×“×™×œ×’×ª×™ ×¢×œ ×™×™×©×•×‘×™×")
                else:
                    print("\nğŸ˜ï¸ ××•×¡×™×£ ×™×™×©×•×‘×™× ×œ-ai_agents.py...")
                    added = self._apply_settlements()
                    total_applied += added
            else:
                print("\nğŸ˜ï¸ ××•×¡×™×£ ×™×™×©×•×‘×™× ×œ-ai_agents.py...")
                added = self._apply_settlements()
                total_applied += added

        # ×¡×™×›×•×
        print("\n" + "=" * 70)
        print(f"âœ… ×¡×™×™××ª×™! ×™×•×©××• {total_applied} ×©×™× ×•×™×™×")
        print("=" * 70)

def main():
    parser = argparse.ArgumentParser(description='ğŸ¯ Tune AI - ××•×˜×•××¦×™×” ×œ×¢×“×›×•×Ÿ ×”×’×“×¨×•×ª')
    parser.add_argument('--apply', action='store_true', help='×™×™×©×•× ××•×˜×•××˜×™ ×©×œ ×›×œ ×”×”××œ×¦×•×ª')
    parser.add_argument('--interactive', action='store_true', help='××¦×‘ ××™× ×˜×¨××§×˜×™×‘×™ - ×‘×—×™×¨×” ×™×“× ×™×ª')
    parser.add_argument('--report', action='store_true', help='×¨×§ ×“×•×— ××¤×•×¨×˜, ×œ×œ× ×©×™× ×•×™×™×')

    args = parser.parse_args()

    # ×‘×“×™×§×ª ×§×‘×¦×™×
    if not os.path.exists("posts.db"):
        print("âŒ posts.db ×œ× × ××¦×! ×”×¨×¥ ××ª ×”××¢×¨×›×ª ×§×•×“×")
        return

    if not os.path.exists("config.json"):
        print("âŒ config.json ×œ× × ××¦×!")
        return

    # ×”×¨×¦×”
    tuner = TuneAI()
    tuner.analyze()

    # ×™×™×©×•× (×× × ×“×¨×©)
    if args.apply:
        tuner.apply_all(interactive=False)
    elif args.interactive:
        tuner.apply_all(interactive=True)

    print("\nâœ… ×¡×™×•×!")

if __name__ == "__main__":
    main()
